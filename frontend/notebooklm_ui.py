"""
Meeting Assistant UI - NotebookLM Style
Clean, modern interface with smooth workflow
"""

import os
import sys
import threading
from typing import Optional
import asyncio
from queue import Queue, Empty
import time
import warnings
import base64
from datetime import datetime

import gradio as gr
import pynini
from punctuators.models import PunctCapSegModelONNX
from dotenv import load_dotenv

load_dotenv()
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from api.services.chunkformer_stt import ChunkFormer
from api.private_config import *
from api.config import *
from api.services.vcdb_faiss import VectorStore
from api.services.local_llm import LanguageModelOllama
from api.services.rag_processor import RagProcessor
from langchain_huggingface.embeddings import HuggingFaceEmbeddings
from api.database.database import SessionLocal
from api.database import crud
from api.services.ollama_mapreduce import OllamaMapReducePipeline, load_config


warnings.filterwarnings("ignore")

# =========================
# GLOBAL STATE
# =========================
current_meeting_id: Optional[int] = None
current_meeting_title: str = ""
current_meeting_context: str = ""

meeting_faiss: Optional[VectorStore] = None
transcript_faiss: Optional[VectorStore] = None
cache_faiss: Optional[VectorStore] = None

# =========================
# ITN MODEL
# =========================
def init_itn_model(itn_model_dir: str):
    far_dir = os.path.join(itn_model_dir, "far")
    classifier_far = os.path.join(far_dir, "classify/tokenize_and_classify.far")
    verbalizer_far = os.path.join(far_dir, "verbalize/verbalize.far")
    
    reader_classifier = pynini.Far(classifier_far)
    reader_verbalizer = pynini.Far(verbalizer_far)
    return reader_classifier.get_fst(), reader_verbalizer.get_fst()

# =========================
# INIT MODELS
# =========================
chunkformer = ChunkFormer(model_checkpoint=CHUNKFORMER_CHECKPOINT)
punc_model = PunctCapSegModelONNX.from_pretrained(
    "1-800-BAD-CODE/xlm-roberta_punctuation_fullstop_truecase",
    ort_providers=["CPUExecutionProvider"],
)
itn_classifier, itn_verbalizer = init_itn_model(ITN_REPO)
llm = LanguageModelOllama("shmily_006/Qw3:4b_4bit", temperature=0.5)
model_embedding = HuggingFaceEmbeddings(
    model_name=MODEL_EMBEDDING,
    model_kwargs={"trust_remote_code": True}
)

config = load_config("/home/bojjoo/Code/EduAssist/api/services/config_ollama_mapreduce.yaml")
mapreduce_pipeline = OllamaMapReducePipeline(config)

# =========================
# QUEUES & LOCKS
# =========================
job_queue = Queue(maxsize=0)
summarizer_queue = Queue(maxsize=0)
embedding_queue = Queue(maxsize=0)

faiss_lock = threading.Lock()
transcript_lock = threading.Lock()
summary_lock = threading.Lock()
db_lock = threading.Lock()

# =========================
# ASYNC LOOP
# =========================
_ASYNC_LOOP: Optional[asyncio.AbstractEventLoop] = None

def start_async_loop():
    global _ASYNC_LOOP
    if _ASYNC_LOOP is None:
        _ASYNC_LOOP = asyncio.new_event_loop()
        t = threading.Thread(target=lambda: asyncio.set_event_loop(_ASYNC_LOOP) or _ASYNC_LOOP.run_forever(), daemon=True)
        t.start()

def run_async(coro, timeout=None):
    return asyncio.run_coroutine_threadsafe(coro, _ASYNC_LOOP).result(timeout=timeout)

start_async_loop()

# =========================
# UI STATE
# =========================
asr_thread: Optional[threading.Thread] = None
stop_event = threading.Event()
transcript_text = ""
summary_text = ""

rag_processor = RagProcessor(
    job_queue=job_queue,
    embedding_queue=embedding_queue,
    n_commits_to_combine=3,
    overlap_m=1,
    timeout_sec=15.0,
)

# =========================
# WORKERS
# =========================
def worker_loop(worker_id: int):
    while True:
        try:
            text = job_queue.get(timeout=1.0)
        except Empty:
            continue
        
        try:
            normalize_prompt = llm.normalize_text(current_meeting_context, text)
            normalized = run_async(llm.async_generate(normalize_prompt), timeout=60.0)
            
            if not normalized or normalized.strip().casefold() == "none":
                continue
            
            if cache_faiss and cache_faiss.is_already_retrieved(normalized, similarity_threshold=0.7):
                continue
            
            related_docs = ""
            if meeting_faiss:
                related_docs = run_async(meeting_faiss.hybrid_search(normalized), timeout=60.0)
            
            summarizer_queue.put({"utterance": normalized, "related_docs": related_docs})
            
            if cache_faiss:
                with faiss_lock:
                    cache_faiss.add_cache(normalized)
        except Exception as e:
            print(f"[Worker-{worker_id}] ERROR: {e}")
        finally:
            job_queue.task_done()

def embedding_worker():
    while True:
        try:
            item = embedding_queue.get(timeout=1.0)
        except Empty:
            continue
        
        try:
            if isinstance(item, dict):
                clean_text = (item.get("text") or "").strip()
                start_ms = item.get("start_time_ms", 0)
                end_ms = item.get("end_time_ms", 0)
            else:
                clean_text = (item or "").strip()
                start_ms = end_ms = 0
            
            if clean_text and transcript_faiss:
                with faiss_lock:
                    transcript_faiss.add_transcript(clean_text, start_ms, end_ms)
        except Exception as e:
            print(f"[EmbeddingWorker] ERROR: {e}")
        finally:
            try:
                embedding_queue.task_done()
            except:
                pass

def summarizer_loop():
    global summary_text
    while True:
        try:
            item = summarizer_queue.get(timeout=1.0)
        except Empty:
            continue
        
        try:
            utter = item.get("utterance", "")
            docs = item.get("related_docs", "")
            
            sum_prompt = SUMMARIZE_DOCUMENT_PROMPT.format(utterance=utter, related_docs=docs)
            summary = run_async(llm.async_generate(sum_prompt), timeout=60.0)
            
            with summary_lock:
                if summary_text:
                    summary_text = f"{summary_text}\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n{summary.strip()}"
                else:
                    summary_text = summary.strip()
            
            # L∆∞u summary v√†o database
            if current_meeting_id and summary.strip():
                try:
                    db = SessionLocal()
                    try:
                        crud.create_summarize(
                            db=db,
                            meeting_id=current_meeting_id,
                            content=summary.strip(),
                            summary_type="realtime",
                            title=f"Summary at {datetime.now().strftime('%H:%M:%S')}"
                        )
                    finally:
                        db.close()
                except Exception as db_err:
                    print(f"[Summarizer] DB ERROR: {db_err}")
        except Exception as e:
            print(f"[Summarizer] ERROR: {e}")
        finally:
            try:
                summarizer_queue.task_done()
            except:
                pass

# Start workers
for i in range(2):
    threading.Thread(target=worker_loop, args=(i+1,), daemon=True).start()
threading.Thread(target=summarizer_loop, daemon=True).start()
threading.Thread(target=embedding_worker, daemon=True).start()

# =========================
# CHUNKFORMER CALLBACK
# =========================
def on_update(event: str, payload: dict):
    global transcript_text
    
    with transcript_lock:
        if event == "partial":
            display = (payload.get("display") or "").strip()
            if display:
                transcript_text = display
        
        elif event == "commit":
            display = (payload.get("display") or payload.get("committed") or "").strip()
            if display:
                transcript_text = display
            
            new_commit = (payload.get("new_commit") or "").strip()
            if new_commit:
                rag_processor.process_new_commit(payload)
        
        elif event == "final_flush":
            text = (payload.get("text") or "").strip()
            if text:
                transcript_text = text
            rag_processor.flush_all(reason="final_flush")

# =========================
# ASR WORKER
# =========================
def asr_worker():
    try:
        chunkformer.chunkformer_asr_realtime_punc_norm(
            mic_sr=16000, stream_chunk_sec=0.5, lookahead_sec=0.5,
            left_context_size=128, right_context_size=32, max_overlap_match=32,
            vad_threshold=0.01, vad_min_silence_blocks=2,
            punc_model=punc_model, punc_window_words=100, punc_commit_margin_words=50,
            itn_classifier=itn_classifier, itn_verbalizer=itn_verbalizer,
            on_update=on_update, stop_event=stop_event, return_final=False,
        )
    except Exception as e:
        print(f"[ASR] Error: {e}")

# =========================
# DATABASE FUNCTIONS
# =========================
def create_meeting(title: str, description: str):
    global current_meeting_id, current_meeting_title, current_meeting_context
    global meeting_faiss, transcript_faiss, cache_faiss
    
    if not title.strip():
        return "‚ö†Ô∏è Vui l√≤ng nh·∫≠p ti√™u ƒë·ªÅ cu·ªôc h·ªçp", gr.update(visible=False)
    
    try:
        db = SessionLocal()
        try:
            meeting = crud.create_meeting(db, title=title, description=description)
            current_meeting_id = meeting.id
            current_meeting_title = meeting.title
            current_meeting_context = ""
            
            folder = f"meeting_{meeting.id}"
            meeting_faiss = VectorStore(folder+"/documents", model_embedding)
            transcript_faiss = VectorStore(folder+"/transcripts", model_embedding)
            cache_faiss = VectorStore(folder+"/cache", model_embedding)
            
            msg = f"""
### ‚úÖ Cu·ªôc h·ªçp ƒë√£ ƒë∆∞·ª£c t·∫°o!

**{title}**  
ID: `{meeting.id}` | Status: `{meeting.status}`

{description if description else '_Kh√¥ng c√≥ m√¥ t·∫£_'}

---
üìé **B∆∞·ªõc ti·∫øp theo:** Upload t√†i li·ªáu li√™n quan ƒë·∫øn cu·ªôc h·ªçp
"""
            return msg, gr.update(visible=True)
        finally:
            db.close()
    except Exception as e:
        return f"‚ùå L·ªói: {e}", gr.update(visible=False)

def upload_documents(files):
    global current_meeting_context
    
    if current_meeting_id is None:
        return "‚ö†Ô∏è Vui l√≤ng t·∫°o cu·ªôc h·ªçp tr∆∞·ªõc!", ""
    
    if not files:
        return "‚ö†Ô∏è Vui l√≤ng ch·ªçn √≠t nh·∫•t m·ªôt t√†i li·ªáu!", ""
    
    try:
        db = SessionLocal()
        try:
            all_chunks = []
            doc_names = []
            
            for file in files:
                filename = os.path.basename(file.name)
                file_type = os.path.splitext(filename)[1].lower().replace('.', '')
                file_size = os.path.getsize(file.name) if os.path.exists(file.name) else 0
                
                doc = crud.create_document(
                    db=db, meeting_id=current_meeting_id,
                    filename=filename, file_path=file.name,
                    file_type=file_type, file_size=file_size
                )
                doc_names.append(filename)
                
                chunks = meeting_faiss.recursive_chunking(file.name)
                all_chunks.extend(chunks)
                
                crud.update_document_embedding(
                    db=db, document_id=doc.id,
                    vector_store_path=f"./vectorstores/meeting_{current_meeting_id}/documents",
                    embedding_model=MODEL_EMBEDDING, chunk_count=len(chunks)
                )
            
            if all_chunks:
                faiss_db = meeting_faiss.create_vectorstore(all_chunks)
                meeting_faiss.faiss_save_local(faiss_db, "")
                # meeting_faiss.db = faiss_db
                meeting_faiss.load_vectorstore()

                documents = ""
                for i in chunks[:25]:
                    documents += i.page_content + "\n-----\n"


                question = "T√†i li·ªáu n√†y n√≥i v·ªÅ v·∫•n ƒë·ªÅ g√¨, c√≥ nh·ªØng kh√°i ni·ªám n√†o c·∫ßn l∆∞u √Ω, h√£y tr·∫£ l·ªùi theo format 'Meeting Context:'"
                current_meeting_context = mapreduce_pipeline.run(documents, question, chunk_size=4096)

                crud.update_meeting(
                    db=db, meeting_id=current_meeting_id,
                    meeting_context=current_meeting_context
                )
            
            msg = f"""
### ‚úÖ T√†i li·ªáu ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω!

**ƒê√£ upload:** {len(doc_names)} t√†i li·ªáu  
**Chunks:** {len(all_chunks)} ƒëo·∫°n vƒÉn b·∫£n  

üìÑ Files:
{chr(10).join([f'- {name}' for name in doc_names])}

---
üé§ **B∆∞·ªõc ti·∫øp theo:** Chuy·ªÉn sang tab "Ghi √¢m" ƒë·ªÉ b·∫Øt ƒë·∫ßu cu·ªôc h·ªçp
"""
            preview = current_meeting_context
            return msg, preview
        finally:
            db.close()
    except Exception as e:
        return f"‚ùå L·ªói: {e}", ""

def start_recording():
    global asr_thread, transcript_text, summary_text
    
    if current_meeting_id is None:
        return gr.update(), gr.update(), "‚ö†Ô∏è Ch∆∞a t·∫°o cu·ªôc h·ªçp!"
    
    try:
        db = SessionLocal()
        try:
            crud.update_meeting(db, current_meeting_id, status="in_progress")
        finally:
            db.close()
    except:
        pass
    
    with transcript_lock:
        transcript_text = ""
    with summary_lock:
        summary_text = ""
    
    stop_event.clear()
    
    if asr_thread is None or not asr_thread.is_alive():
        asr_thread = threading.Thread(target=asr_worker, daemon=True)
        asr_thread.start()
        return gr.update(value=""), gr.update(value=""), "üéôÔ∏è ƒêang ghi √¢m..."
    else:
        return gr.update(), gr.update(), "‚úÖ ƒêang ghi √¢m"

def stop_recording():
    global transcript_text
    
    if current_meeting_id is None:
        return "‚ö†Ô∏è Ch∆∞a c√≥ cu·ªôc h·ªçp!", gr.update(visible=False)
    
    stop_event.set()
    rag_processor.flush_all(reason="stop")
    
    try:
        db = SessionLocal()
        try:
            with transcript_lock:
                final = transcript_text
            
            if final.strip():
                crud.create_transcript(
                    db=db, meeting_id=current_meeting_id,
                    content=final, duration_ms=0, language="vi"
                )
            
            crud.update_meeting(db, current_meeting_id, status="completed")
        finally:
            db.close()
        
        # Hi·ªÉn th·ªã modal x√°c nh·∫≠n t·∫°o bi√™n b·∫£n
        return "‚èπÔ∏è ƒê√£ d·ª´ng v√† l∆∞u transcript", gr.update(visible=True)
    except Exception as e:
        return f"‚ö†Ô∏è L·ªói: {e}", gr.update(visible=False)


def generate_meeting_minutes():
    """
    T·∫°o bi√™n b·∫£n cu·ªôc h·ªçp b·∫±ng MapReduce pipeline
    """
    global transcript_text

    if current_meeting_id is None:
        return (
            "‚ö†Ô∏è Ch∆∞a c√≥ cu·ªôc h·ªçp!",
            gr.update(visible=False),  # minutes_modal
            "",  # minutes_display
            gr.update(open=False)  # minutes_accordion
        )

    try:
        with transcript_lock:
            document = transcript_text

        if not document.strip():
            return (
                "‚ö†Ô∏è Kh√¥ng c√≥ transcript ƒë·ªÉ t·∫°o bi√™n b·∫£n!",
                gr.update(visible=False),
                "",
                gr.update(open=False)
            )

        # Ch·∫°y MapReduce pipeline
        question = "T√≥m t·∫Øt c√°c √Ω ch√≠nh c·ªßa cu·ªôc h·ªçp, tr√¨nh b√†y r√µ r√†ng th√†nh t·ª´ng m·ª•c n·∫øu c·∫ßn thi·∫øt"
        result = mapreduce_pipeline.run(document, question, chunk_size=4096)

        # L∆∞u bi√™n b·∫£n v√†o database (vd: description)
        db = SessionLocal()
        try:
            crud.update_meeting(
                db=db,
                meeting_id=current_meeting_id,
                description=f"{result}\n\n---\n_Bi√™n b·∫£n ƒë∆∞·ª£c t·∫°o t·ª± ƒë·ªông t·ª´ transcript_"
            )
        finally:
            db.close()

        # ‚úÖ Tr·∫£ v·ªÅ: status, ·∫©n modal, n·ªôi dung bi√™n b·∫£n, M·ªû accordion
        return (
            "‚úÖ ƒê√£ t·∫°o bi√™n b·∫£n cu·ªôc h·ªçp th√†nh c√¥ng!",
            gr.update(visible=False),  # ·∫©n modal
            result,  # HI·ªÇN TH·ªä FULL BI√äN B·∫¢N
            gr.update(open=True)  # m·ªü accordion
        )

    except Exception as e:
        return (
            f"‚ùå L·ªói khi t·∫°o bi√™n b·∫£n: {e}",
            gr.update(visible=False),
            "",
            gr.update(open=False)
        )


def cancel_meeting_minutes():
    """H·ªßy t·∫°o bi√™n b·∫£n"""
    return (
        "‚ÑπÔ∏è ƒê√£ h·ªßy t·∫°o bi√™n b·∫£n",
        gr.update(visible=False),   # ·∫©n modal
        "",                         # clear minutes_display
        gr.update(open=False)       # ƒë√≥ng accordion
    )


def poll_ui():
    with transcript_lock:
        txt = transcript_text
    with summary_lock:
        sumtxt = summary_text
    return gr.update(value=txt), gr.update(value=sumtxt)

def chat_qa(history, message):
    if current_meeting_id is None:
        return (history or []) + [(message, "‚ö†Ô∏è Vui l√≤ng t·∫°o cu·ªôc h·ªçp tr∆∞·ªõc!")], ""
    
    if not message:
        return history, ""
    
    try:
        db = SessionLocal()
        try:
            db_history = crud.get_conversation_history(db, current_meeting_id, last_n=5)
            history_str = "\n\n".join([
                f"{'User' if h['role']=='human' else 'AI'}: {h['content']}" 
                for h in db_history
            ])
            
            reformulated = run_async(
                llm.reformulate_question(message, history_str, current_meeting_context),
                timeout=60.0
            )
            
            if reformulated.get("type") == 0:
                reply = run_async(
                    llm.normal_qa_handler(
                        reformulated["new_question"],
                        history_str, current_meeting_context
                    ), timeout=60.0
                )
            else:
                related_docs = ""
                related_transcript = ""
                
                if meeting_faiss:
                    related_docs = run_async(
                        meeting_faiss.hybrid_search(reformulated["new_question"]),
                        timeout=60.0
                    )
                
                if transcript_faiss and transcript_faiss.db:
                    related_transcript = run_async(
                        transcript_faiss.hybrid_search(reformulated["new_question"]),
                        timeout=60.0
                    )
                
                reply = run_async(
                    llm.rag_qa_handler(
                        reformulated["new_question"], history_str,
                        current_meeting_context, related_docs, related_transcript
                    ), timeout=60.0
                )
            
            crud.add_message(db, current_meeting_id, role="human", content=message)
            crud.add_message(db, current_meeting_id, role="ai", content=reply,
                           extra_data={"sources": ["documents", "transcripts"]})
        finally:
            db.close()
        
        return (history or []) + [(message, reply)], ""
    except Exception as e:
        return (history or []) + [(message, f"‚ùå L·ªói: {e}")], ""

def load_meetings():
    try:
        db = SessionLocal()
        try:
            meetings = crud.get_all_meetings(db, skip=0, limit=50)
            choices = [(f"{m.title} (ID: {m.id})", m.id) for m in meetings]
            return gr.update(choices=choices)
        finally:
            db.close()
    except:
        return gr.update(choices=[])


def select_meeting(meeting_id):
    global current_meeting_id, current_meeting_title, current_meeting_context
    global meeting_faiss, transcript_faiss, cache_faiss
    global transcript_text, summary_text

    if not meeting_id:
        return "‚ö†Ô∏è Vui l√≤ng ch·ªçn cu·ªôc h·ªçp!", "", "", "", "", []

    try:
        db = SessionLocal()
        try:
            meeting = crud.get_meeting(db, meeting_id)
            if not meeting:
                return "‚ùå Kh√¥ng t√¨m th·∫•y cu·ªôc h·ªçp!", "", "", "", "", []

            current_meeting_id = meeting.id
            current_meeting_title = meeting.title
            current_meeting_context = meeting.meeting_context or ""

            folder = f"meeting_{meeting.id}"
            meeting_faiss = VectorStore(folder + "/documents", model_embedding)
            transcript_faiss = VectorStore(folder + "/transcripts", model_embedding)
            cache_faiss = VectorStore(folder + "/cache", model_embedding)

            docs = crud.get_documents(db, meeting_id)
            transcript = crud.get_transcript(db, meeting_id)
            messages = crud.get_messages(db, meeting_id)
            summaries = crud.get_summarizes(db, meeting_id)

            # Load transcript v√†o transcript_text
            with transcript_lock:
                transcript_text = transcript.content if transcript else ""
            
            # Load summaries v√†o summary_text
            with summary_lock:
                if summaries:
                    summary_parts = []
                    for s in summaries:
                        summary_parts.append(s.content)
                    summary_text = "\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n".join(summary_parts)
                else:
                    summary_text = ""
            
            # T·∫°o chatbot history t·ª´ messages
            chatbot_history = []
            for msg in messages:
                if msg.role == "human":
                    # T√¨m message AI ti·∫øp theo
                    ai_msg = None
                    msg_index = messages.index(msg)
                    if msg_index + 1 < len(messages) and messages[msg_index + 1].role == "ai":
                        ai_msg = messages[msg_index + 1]
                        chatbot_history.append((msg.content, ai_msg.content))

            # HEADER ng·∫Øn
            header_md = f"""### üìã {meeting.title}

ID: `{meeting.id}` ¬∑ Status: `{meeting.status}`
"""

            # Danh s√°ch t√†i li·ªáu
            if docs:
                doc_lines = "\n".join([f"- {d.filename}" for d in docs[:20]])
                docs_block = f"üìÑ **Danh s√°ch t√†i li·ªáu ({len(docs)}):**\n{doc_lines}"
            else:
                docs_block = "üìÑ **Danh s√°ch t√†i li·ªáu:** _Ch∆∞a c√≥ t√†i li·ªáu n√†o_"

            # Meeting context
            if meeting.meeting_context:
                ctx = meeting.meeting_context.strip()
                if len(ctx) > 1200:
                    ctx = ctx[:1200] + "..."
                context_block = f"üß† **Meeting Context:**\n\n{ctx}"
            else:
                context_block = "üß† **Meeting Context:** _Ch∆∞a c√≥ meeting context_"

            detail_md = f"""
**Transcript:** {'‚úÖ' if transcript else '‚ùå'} ({transcript.word_count if transcript else 0} t·ª´)  
**Tin nh·∫Øn:** {len(messages)} messages  
**Summaries:** {len(summaries)} t√≥m t·∫Øt

**M√¥ t·∫£:** {meeting.description or '_Kh√¥ng c√≥ m√¥ t·∫£_'}

---
{docs_block}

---
{context_block}
"""

            status_msg = f"‚úÖ ƒê√£ load cu·ªôc h·ªçp ID={meeting.id}"
            return status_msg, header_md, detail_md, transcript_text, summary_text, chatbot_history
        finally:
            db.close()
    except Exception as e:
        return f"‚ùå L·ªói: {e}", "", "", "", "", []


import re

def load_meeting_cards():
    """
    Tr·∫£ v·ªÅ danh s√°ch meetings ƒë·ªÉ hi·ªÉn th·ªã d·∫°ng card tr√™n trang ch·ªß.
    M·ªói ph·∫ßn t·ª≠ l√† m·ªôt list [markdown_text] ƒë·ªÉ d√πng v·ªõi gr.Dataset.
    """
    try:
        db = SessionLocal()
        try:
            meetings = crud.get_all_meetings(db, skip=0, limit=50)
            samples = []
            for m in meetings:
                desc = (m.description or "").strip()
                if len(desc) > 80:
                    desc = desc[:77] + "..."
                status = (m.status or "").strip()
                status_icon = "üü¢" if status == "in_progress" else ("‚úÖ" if status == "completed" else "üìÅ")
                md = f"""**{m.title}**  

ID: `{m.id}` ¬∑ {status_icon} `{status}`  

_{desc or "Kh√¥ng c√≥ m√¥ t·∫£"}_
"""
                samples.append([md])
            return gr.update(samples=samples)
        finally:
            db.close()
    except Exception as e:
        print("[load_meeting_cards] ERROR:", e)
        return gr.update(samples=[])


def open_meeting_from_card(sample):
    """
    sample l√† [markdown_text] t·ª´ Dataset.
    Tr·∫£ v·ªÅ:
    - ·∫®n home_view, hi·ªán meeting_view
    - C·∫≠p nh·∫≠t meeting_header_box
    - C·∫≠p nh·∫≠t status_box
    - C·∫≠p nh·∫≠t n·ªôi dung chi ti·∫øt (meeting_detail_box) nh∆∞ng v·∫´n ·∫©n
    - Load transcript, summary v√† chatbot history
    """
    if not sample or not sample[0]:
        return (
            gr.update(visible=True),    # home_view
            gr.update(visible=False),   # meeting_view
            "### üìã Ch∆∞a ch·ªçn cu·ªôc h·ªçp",# meeting_header_box
            "_Ch∆∞a b·∫Øt ƒë·∫ßu_",           # status_box
            "",                         # meeting_detail_box
            gr.update(visible=False),   # meeting_detail_group
            "",                         # transcript_display
            "",                         # summary_display
            [],                         # chatbot
        )
    text = sample[0]
    m = re.search(r"ID:\s*`(\d+)`", text)
    if not m:
        return (
            gr.update(visible=True),
            gr.update(visible=False),
            "### üìã Ch∆∞a ch·ªçn cu·ªôc h·ªçp",
            "_Ch∆∞a b·∫Øt ƒë·∫ßu_",
            "",
            gr.update(visible=False),
            "",
            "",
            [],
        )
    meeting_id = int(m.group(1))
    status_msg, header_md, detail_md, transcript_txt, summary_txt, chatbot_hist = select_meeting(meeting_id)

    return (
        gr.update(visible=False),   # home_view ·∫©n
        gr.update(visible=True),    # meeting_view hi·ªán
        header_md,                  # meeting_header_box
        status_msg,                 # status_box
        detail_md,                  # meeting_detail_box (ch∆∞a hi·ªán, ch·ªâ set content)
        gr.update(visible=False),   # meeting_detail_group: v·∫´n ·∫©n, ch·ªù b·∫•m "xem chi ti·∫øt"
        transcript_txt,             # transcript_display
        summary_txt,                # summary_display
        chatbot_hist,               # chatbot history
    )



def create_meeting_and_go(title: str, description: str):
    msg, _ = create_meeting(title, description)   # create_meeting ƒë√£ set current_meeting_id

    header_md = ""
    detail_md = ""
    try:
        if current_meeting_id is not None:
            db = SessionLocal()
            try:
                meeting = crud.get_meeting(db, current_meeting_id)
                if meeting:
                    docs = crud.get_documents(db, meeting.id)

                    # HEADER ng·∫Øn
                    header_md = f"""### üìã {meeting.title}

ID: `{meeting.id}` ¬∑ Status: `{meeting.status}`
"""

                    # docs
                    if docs:
                        doc_lines = "\n".join([f"- {d.filename}" for d in docs[:20]])
                        docs_block = f"üìÑ **Danh s√°ch t√†i li·ªáu ({len(docs)}):**\n{doc_lines}"
                    else:
                        docs_block = "üìÑ **Danh s√°ch t√†i li·ªáu:** _Ch∆∞a c√≥ t√†i li·ªáu n√†o_"

                    # context
                    ctx = (meeting.meeting_context or "").strip()
                    if ctx:
                        if len(ctx) > 1200:
                            ctx = ctx[:1200] + "..."
                        context_block = f"üß† **Meeting Context:**\n\n{ctx}"
                    else:
                        context_block = "üß† **Meeting Context:** _Ch∆∞a c√≥ meeting context_"

                    detail_md = f"""
**M√¥ t·∫£:** {meeting.description or '_Kh√¥ng c√≥ m√¥ t·∫£_'}
---
{docs_block}
---
{context_block}
"""
            finally:
                db.close()
    except Exception as e:
        print("[create_meeting_and_go] ERROR:", e)

    return (
        msg,                        # create_status
        header_md,                  # meeting_header_box
        gr.update(visible=False),   # home_view
        gr.update(visible=True),    # meeting_view
        detail_md,                  # meeting_detail_box
        gr.update(visible=False),   # meeting_detail_group (·∫©n, ch·ªù b·∫•m "xem chi ti·∫øt")
    )


def go_home():
    """
    Quay l·∫°i trang ch·ªß, reset transcript/summary/chatbot & d·ª´ng ghi √¢m n·∫øu c√≤n.
    ƒê·ªìng th·ªùi ·∫©n box chi ti·∫øt meeting.
    """
    global transcript_text, summary_text
    stop_event.set()
    with transcript_lock:
        transcript_text = ""
    with summary_lock:
        summary_text = ""

    return (
        gr.update(visible=True),    # home_view
        gr.update(visible=False),   # meeting_view
        "_Ch∆∞a b·∫Øt ƒë·∫ßu_",           # status_box
        "",                         # transcript_display
        "",                         # summary_display
        [],                         # chatbot (clear history)
        gr.update(visible=False),   # meeting_detail_group
        "",                         # meeting_detail_box
    )

# =========================
# GRADIO UI - NotebookLM Style
# =========================

# =========================
# HELPER: ENCODE LOGO
# =========================
def get_logo_base64():
    logo_path = "../images/vimeeting_logo.png"
    try:
        with open(logo_path, "rb") as f:
            encoded = base64.b64encode(f.read()).decode()
            return f"data:image/png;base64,{encoded}"
    except Exception as e:
        print(f"[LOGO] Error loading logo: {e}")
        return ""

custom_css = """
.gradio-container {
    max-width: none !important;
    width: 100% !important;
    padding: 0 24px 40px 24px;
}
.tab-nav button {
    font-size: 16px;
    font-weight: 500;
}
.meeting-header {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    padding: 24px 32px;
    border-radius: 16px;
    margin: 16px 0 24px 0;
    display: flex;
    align-items: center;
    justify-content: space-between;
}
.meeting-header h1 {
    margin: 0;
}
.meeting-header img {
    border-radius: 8px;
    box-shadow: 0 2px 6px rgba(0,0,0,0.2);
}
.home-title {
    font-size: 20px;
    font-weight: 600;
    margin-bottom: 8px;
}
.home-subtitle {
    color: #9ca3af;
    margin-bottom: 24px;
}
#meeting-grid .wrap {
    display: flex;
    flex-wrap: wrap;
    gap: 20px;
}
#meeting-grid .wrap > div {
    flex: 0 0 260px;
}
#meeting-grid .wrap > div > div {
    background: #111827;
    border-radius: 18px;
    padding: 16px 18px;
    box-shadow: 0 4px 18px rgba(0,0,0,0.25);
    cursor: pointer;
    transition: transform 0.12s ease, box-shadow 0.12s ease, background 0.12s ease;
}
#meeting-grid .wrap > div > div:hover {
    transform: translateY(-2px);
    box-shadow: 0 8px 24px rgba(0,0,0,0.35);
    background: #1f2937;
}
.upload-zone {
    border: 2px dashed #4f46e5;
    border-radius: 12px;
    padding: 20px;
    background: #020617;
}
.chat-container {
    border-radius: 16px;
    box-shadow: 0 2px 16px rgba(0,0,0,0.35);
}
"""

with gr.Blocks(title="ViMeeting - NotebookLM Style", css=custom_css, theme=gr.themes.Soft()) as demo:
    logo_base64 = get_logo_base64()
    gr.HTML(f"""
        <div style="display: flex; align-items: center; gap: 12px;">
            <img src="{logo_base64}" alt="logo" style="height:48px; width:auto;">
            <div>
                <h1 style="margin:0; font-size:28px;">ViMeeting</h1>
                <p style="margin:0; font-size:14px; color:#e0e0e0;">Powered by DataFlow</p>
            </div>
        </div>
    """)
    with gr.Column(scale=0.5):
        gr.Markdown("T·∫°o, qu·∫£n l√Ω v√† ghi √¢m c√°c cu·ªôc h·ªçp c·ªßa b·∫°n.")


    # ==================== HOME PAGE ====================
    with gr.Column(visible=True) as home_view:
        gr.Markdown(
            "## S·ªï ghi ch√∫ c·ªßa t√¥i\n"
            "C√°c cu·ªôc h·ªçp s·∫Ω xu·∫•t hi·ªán t·∫°i ƒë√¢y gi·ªëng nh∆∞ c√°c notebook trong NotebookLM.",
            elem_classes=["home-title"]
        )

        # H√†ng n√∫t t·∫°o v√† l√†m m·ªõi
        with gr.Row():
            create_new_btn = gr.Button("‚ûï T·∫°o cu·ªôc h·ªçp m·ªõi", variant="primary", size="sm", scale=0)
            refresh_home_btn = gr.Button("üîÑ", size="sm", variant="secondary", scale=0)

        # Form t·∫°o cu·ªôc h·ªçp ‚Äî ·∫©n m·∫∑c ƒë·ªãnh
        # === FORM T·∫†O CU·ªòC H·ªåP ===
        with gr.Group(visible=False) as create_meeting_box:
            with gr.Column():  # üëà Bao t·∫•t c·∫£ trong 1 Column duy nh·∫•t, kh√¥ng d√πng Row ƒë·∫ßu ti√™n
                meeting_title = gr.Textbox(
                    label="Ti√™u ƒë·ªÅ cu·ªôc h·ªçp",
                    placeholder="VD: H·ªçp k·∫ø ho·∫°ch Q1 2025",
                    lines=1
                )

                meeting_desc = gr.Textbox(
                    label="M√¥ t·∫£ (t√πy ch·ªçn)",
                    placeholder="Th·∫£o lu·∫≠n k·∫ø ho·∫°ch kinh doanh v√† m·ª•c ti√™u...",
                    lines=3
                )

                with gr.Row():
                    create_btn = gr.Button("‚úÖ T·∫°o", variant="primary")
                    cancel_create_btn = gr.Button("‚ùå H·ªßy", variant="secondary")

                create_status = gr.Markdown("")

        # Danh s√°ch meetings
        gr.Markdown("### üìö C√°c cu·ªôc h·ªçp c·ªßa t√¥i")

        meetings_grid = gr.Dataset(
            label="",
            components=[gr.Markdown()],
            samples=[],
            elem_id="meeting-grid"
        )

    # ==================== MEETING PAGE ====================
    with gr.Column(visible=False) as meeting_view:
        # Top bar: Back + header + n√∫t xem chi ti·∫øt
        with gr.Row():
            back_btn = gr.Button("‚¨ÖÔ∏è V·ªÅ trang ch·ªß", variant="secondary", size="sm", scale=0)
            meeting_header_box = gr.Markdown("### üìã Ch∆∞a ch·ªçn cu·ªôc h·ªçp")

        with gr.Row():
            detail_btn = gr.Button("‚ÑπÔ∏è Xem chi ti·∫øt", size="sm", variant="secondary", scale=0)

        # Box chi ti·∫øt (·∫©n m·∫∑c ƒë·ªãnh)
        with gr.Group(visible=False) as meeting_detail_group:
            meeting_detail_box = gr.Markdown("")

        with gr.Accordion("üìé T√†i li·ªáu cu·ªôc h·ªçp", open=False):
            with gr.Row(elem_classes=["upload-zone"]):
                with gr.Column():
                    file_input = gr.File(
                        label="Ch·ªçn t√†i li·ªáu",
                        file_count="multiple",
                        file_types=[".pdf", ".docx", ".txt"]
                    )
                    upload_btn = gr.Button("üì§ Upload & Ph√¢n t√≠ch", variant="primary", size="lg")
            upload_status = gr.Markdown("")
            context_box = gr.Textbox(
                label="Meeting Context (r√∫t ra t·ª± ƒë·ªông t·ª´ t√†i li·ªáu)",
                lines=6,
                interactive=False
            )

        # Ghi √¢m + Q&A
        with gr.Row():
            start_btn = gr.Button("‚ñ∂Ô∏è B·∫Øt ƒë·∫ßu ghi √¢m", variant="primary", size="lg")
            stop_btn = gr.Button("‚èπÔ∏è D·ª´ng ghi √¢m", variant="stop", size="lg")
            status_box = gr.Markdown("_Ch∆∞a b·∫Øt ƒë·∫ßu_")
        
        # Modal x√°c nh·∫≠n t·∫°o bi√™n b·∫£n
        with gr.Group(visible=False) as minutes_modal:
            gr.Markdown("### üìù T·∫°o bi√™n b·∫£n cu·ªôc h·ªçp?")
            gr.Markdown("B·∫°n c√≥ mu·ªën t·∫°o bi√™n b·∫£n t·ªïng h·ª£p t·ª´ transcript c·ªßa cu·ªôc h·ªçp kh√¥ng?")
            with gr.Row():
                create_minutes_btn = gr.Button("‚úÖ C√≥, t·∫°o bi√™n b·∫£n", variant="primary", size="lg")
                cancel_minutes_btn = gr.Button("‚ùå Kh√¥ng, b·ªè qua", variant="secondary", size="lg")
            minutes_status = gr.Markdown("")
        
        # Box hi·ªÉn th·ªã bi√™n b·∫£n
        with gr.Accordion("üìú Bi√™n b·∫£n cu·ªôc h·ªçp", open=False) as minutes_accordion:
            minutes_display = gr.Textbox(
                show_label=False,
                placeholder="Bi√™n b·∫£n s·∫Ω ƒë∆∞·ª£c hi·ªÉn th·ªã ·ªü ƒë√¢y sau khi t·∫°o...",
                lines=20,
                interactive=False,
                max_lines=30
            )

        with gr.Row():
            with gr.Column(scale=2):
                gr.Markdown("### üìÑ Transcript")
                transcript_display = gr.Textbox(
                    show_label=False,
                    placeholder="Transcript s·∫Ω hi·ªÉn th·ªã ·ªü ƒë√¢y khi b·∫Øt ƒë·∫ßu ghi √¢m...",
                    lines=30,
                    interactive=False,
                    max_lines=30
                )

            with gr.Column(scale=3, elem_classes=["chat-container"]):
                gr.Markdown("### üí¨ H·ªèi ƒë√°p")
                chatbot = gr.Chatbot(
                    show_label=False,
                    height=650,
                    bubble_full_width=False,
                    avatar_images=(None, "https://cdn-icons-png.flaticon.com/512/4712/4712109.png")
                )
                with gr.Row():
                    chat_msg = gr.Textbox(
                        show_label=False,
                        placeholder="üí≠ ƒê·∫∑t c√¢u h·ªèi v·ªÅ cu·ªôc h·ªçp ho·∫∑c t√†i li·ªáu...",
                        lines=2,
                        scale=9
                    )
                    send_btn = gr.Button("üì§", scale=1, variant="primary")

            with gr.Column(scale=2):
                gr.Markdown("### üìä T√≥m t·∫Øt & Insights")
                summary_display = gr.Textbox(
                    show_label=False,
                    placeholder="C√°c ƒëo·∫°n t√≥m t·∫Øt t·ª´ AI s·∫Ω xu·∫•t hi·ªán ·ªü ƒë√¢y...",
                    lines=30,
                    interactive=False,
                    max_lines=30
                )

    # ==================== EVENT HANDLERS ====================
    # Toggle xem/·∫©n chi ti·∫øt
    detail_visible = gr.State(False)


    def toggle_details(current_visible):
        """N·∫øu ƒëang ·∫©n th√¨ hi·ªán, n·∫øu ƒëang hi·ªán th√¨ ·∫©n."""
        if current_visible:
            # ƒëang m·ªü => ·∫©n l·∫°i
            return gr.update(visible=False), False, "‚ÑπÔ∏è Xem chi ti·∫øt"
        else:
            # ƒëang ·∫©n => m·ªü ra
            return gr.update(visible=True), True, "üîΩ ·∫®n chi ti·∫øt"


    demo.load(fn=load_meeting_cards, outputs=[meetings_grid])
    refresh_home_btn.click(fn=load_meeting_cards, outputs=[meetings_grid])


    # Toggle hi·ªÉn th·ªã box t·∫°o cu·ªôc h·ªçp
    def show_create_box():
        return gr.update(visible=True)


    def hide_create_box():
        return gr.update(visible=False)


    create_new_btn.click(fn=show_create_box, outputs=[create_meeting_box])
    cancel_create_btn.click(fn=hide_create_box, outputs=[create_meeting_box])

    create_btn.click(
        fn=create_meeting_and_go,
        inputs=[meeting_title, meeting_desc],
        outputs=[
            create_status,  # msg t·∫°o cu·ªôc h·ªçp
            meeting_header_box,  # header ng·∫Øn tr√™n meeting page
            home_view,  # ·∫©n
            meeting_view,  # hi·ªán
            meeting_detail_box,  # n·ªôi dung chi ti·∫øt (context + docs)
            meeting_detail_group  # group chi ti·∫øt (·∫©n/hi·ªán)
        ]
    )

    meetings_grid.select(
        fn=open_meeting_from_card,
        inputs=[meetings_grid],
        outputs=[home_view, meeting_view, meeting_header_box, status_box, meeting_detail_box, meeting_detail_group,
                transcript_display, summary_display, chatbot]
    )

    back_btn.click(
        fn=go_home,
        outputs=[home_view, meeting_view, status_box, transcript_display, summary_display, chatbot,
                 meeting_detail_group, meeting_detail_box]
    )

    upload_btn.click(
        fn=upload_documents,
        inputs=[file_input],
        outputs=[upload_status, context_box]
    )

    start_btn.click(fn=start_recording, outputs=[transcript_display, summary_display, status_box])
    stop_btn.click(fn=stop_recording, outputs=[status_box, minutes_modal])

    create_minutes_btn.click(
        fn=generate_meeting_minutes,
        outputs=[minutes_status, minutes_modal, minutes_display, minutes_accordion],
        show_progress="full"  # üëà c√°i n√†y s·∫Ω b·∫≠t m√†n h√¨nh loading c·ªßa Gradio
    )

    cancel_minutes_btn.click(
        fn=cancel_meeting_minutes,
        outputs=[minutes_status, minutes_modal, minutes_display, minutes_accordion]
    )

    timer = gr.Timer(value=0.3, active=True)
    timer.tick(fn=poll_ui, outputs=[transcript_display, summary_display])

    send_btn.click(fn=chat_qa, inputs=[chatbot, chat_msg], outputs=[chatbot, chat_msg])
    chat_msg.submit(fn=chat_qa, inputs=[chatbot, chat_msg], outputs=[chatbot, chat_msg])

    detail_btn.click(
        fn=toggle_details,
        inputs=[detail_visible],
        outputs=[meeting_detail_group, detail_visible, detail_btn]
    )

if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=7862, share=False)
